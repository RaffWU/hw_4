{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencc-python-reimplemented in c:\\users\\m\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencc-python-reimplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\m\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: Cython==0.29.21 in c:\\users\\m\\anaconda3\\lib\\site-packages (from gensim) (0.29.21)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from gensim) (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\m\\anaconda3\\lib\\site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#老師給的語料我不知道該怎麼用 所以我從 \"https://dumps.wikimedia.org/zhwiki/\" 下載了另一份語料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 articles processed.\n",
      "20000 articles processed.\n",
      "30000 articles processed.\n",
      "40000 articles processed.\n",
      "50000 articles processed.\n",
      "60000 articles processed.\n",
      "70000 articles processed.\n",
      "80000 articles processed.\n",
      "90000 articles processed.\n",
      "100000 articles processed.\n",
      "110000 articles processed.\n",
      "120000 articles processed.\n",
      "130000 articles processed.\n",
      "140000 articles processed.\n",
      "150000 articles processed.\n",
      "160000 articles processed.\n",
      "170000 articles processed.\n",
      "180000 articles processed.\n",
      "190000 articles processed.\n",
      "200000 articles processed.\n",
      "210000 articles processed.\n",
      "220000 articles processed.\n",
      "230000 articles processed.\n",
      "240000 articles processed.\n",
      "250000 articles processed.\n",
      "250509 articles processed.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore',category=UserWarning,module='gensim')\n",
    "import gensim\n",
    "from gensim.corpora import WikiCorpus\n",
    "\n",
    "wiki_corpus = WikiCorpus('zhwiki-20210801-pages-articles-multistream.xml.bz2', dictionary={})\n",
    "text_num = 0\n",
    "\n",
    "with open('wiki_text.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in wiki_corpus.get_texts():\n",
    "        f.write(' '.join(text)+'\\n')\n",
    "        text_num += 1\n",
    "        if text_num % 10000 == 0:\n",
    "            print('{} articles processed.'.format(text_num))\n",
    "\n",
    "    print('{} articles processed.'.format(text_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import jieba\n",
    "from opencc import OpenCC\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# Initial\n",
    "cc = OpenCC('s2t')\n",
    "\n",
    "\n",
    "# Tokenize\n",
    "with open('wiki_text_seg.txt', 'w', encoding='utf-8') as new_f:\n",
    "    with open('wiki_text.txt', 'r', encoding='utf-8') as f:\n",
    "        for times, data in enumerate(f, 1):\n",
    "            #print('data num:', times)\n",
    "            data = cc.convert(data)\n",
    "            data = jieba.cut(data)\n",
    "            data = [word for word in data if word != ' ']\n",
    "            data = ' '.join(data)\n",
    "\n",
    "            new_f.write(data)\n",
    "\n",
    "# Settings\n",
    "seed = 666\n",
    "sg = 0\n",
    "window_size = 10\n",
    "vector_size = 100\n",
    "min_count = 1\n",
    "workers = 8\n",
    "epochs = 5\n",
    "batch_words = 10000\n",
    "\n",
    "train_data = word2vec.LineSentence('wiki_text_seg.txt')\n",
    "model = word2vec.Word2Vec(\n",
    "    train_data,\n",
    "    min_count=min_count,\n",
    "    vector_size=vector_size,\n",
    "    workers=workers,\n",
    "    epochs=epochs,\n",
    "    window=window_size,\n",
    "    sg=sg,\n",
    "    seed=seed,\n",
    "    batch_words=batch_words\n",
    ")\n",
    "\n",
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
